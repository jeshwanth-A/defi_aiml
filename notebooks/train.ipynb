{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DefiDoza Training Notebook\n",
    "\n",
    "This notebook is self-contained and only for model training.\n",
    "\n",
    "- No local project files required\n",
    "- No LLM/agent code\n",
    "- Trained artifacts saved to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install deps and mount Google Drive\n",
    "!pip -q install numpy==1.26.4 pandas==2.2.0 scikit-learn==1.6.1 torch tensorflow ipywidgets\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_BASE = '/content/drive/MyDrive/defidoza'\n",
    "WEIGHTS_DIR = f'{DRIVE_BASE}/weights'\n",
    "SCALER_PATH = f'{WEIGHTS_DIR}/scaler.pkl'\n",
    "PYTORCH_WEIGHTS = f'{WEIGHTS_DIR}/pytorch_lstm.pth'\n",
    "TF_WEIGHTS = f'{WEIGHTS_DIR}/tf_lstm.h5'\n",
    "RF_WEIGHTS = f'{WEIGHTS_DIR}/rf_model.pkl'\n",
    "\n",
    "import os\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "print('Storage ready at:', WEIGHTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Training UI (ipywidgets)\n",
    "import json\n",
    "import pickle\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "TOKENS = ['uniswap', 'bitcoin', 'ethereum', 'solana', 'cardano']\n",
    "\n",
    "def fetch_and_parse(token_id='uniswap', days=30):\n",
    "    url = f'https://api.coingecko.com/api/v3/coins/{token_id}/market_chart?vs_currency=usd&days={days}&interval=daily'\n",
    "    with urllib.request.urlopen(url) as r:\n",
    "        data = json.loads(r.read().decode('utf-8'))\n",
    "    prices = data.get('prices', [])\n",
    "    volumes = data.get('total_volumes', [])\n",
    "    if not prices:\n",
    "        return None\n",
    "    df = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
    "    df['volume'] = [v[1] for v in volumes]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, fit_scaler=True):\n",
    "    df = df.copy()\n",
    "    np.random.seed(42)\n",
    "    df['sentiment'] = np.random.uniform(-1, 1, size=len(df))\n",
    "    prices = df['price'].values\n",
    "    ws = min(5, len(prices))\n",
    "    if len(prices) >= ws:\n",
    "        vol = np.std(np.lib.stride_tricks.sliding_window_view(prices, ws), axis=1)\n",
    "        df['volatility'] = np.pad(vol, (ws - 1, 0), mode='edge')\n",
    "    else:\n",
    "        df['volatility'] = 0\n",
    "\n",
    "    cols = ['price', 'volume', 'sentiment', 'volatility']\n",
    "    if fit_scaler:\n",
    "        scaler = MinMaxScaler()\n",
    "        df[cols] = scaler.fit_transform(df[cols])\n",
    "        with open(SCALER_PATH, 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "    else:\n",
    "        with open(SCALER_PATH, 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        df[cols] = scaler.transform(df[cols])\n",
    "\n",
    "    df['price_lag1'] = df['price'].shift(1)\n",
    "    return df.dropna(), scaler\n",
    "\n",
    "def create_sequences(data, seq_len=10):\n",
    "    seq_len = min(seq_len, len(data) - 1)\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data.iloc[i:i + seq_len].values)\n",
    "        y.append(data.iloc[i + seq_len]['price'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=50, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "def create_tf_model(shape):\n",
    "    m = Sequential([LSTM(50, input_shape=shape), Dense(1)])\n",
    "    m.compile(optimizer='adam', loss='mse')\n",
    "    return m\n",
    "\n",
    "def create_rf_model():\n",
    "    return RandomForestRegressor(n_estimators=50, random_state=42, max_depth=10)\n",
    "\n",
    "def train_pytorch(X, y, epochs, log):\n",
    "    log(f'Training PyTorch ({epochs} epochs)...')\n",
    "    m = PricePredictor(input_size=X.shape[2])\n",
    "    dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    m = m.to(dev)\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=0.001)\n",
    "    crit = nn.MSELoss()\n",
    "    Xt = torch.tensor(X, dtype=torch.float32).to(dev)\n",
    "    yt = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(dev)\n",
    "    for e in range(epochs):\n",
    "        m.train()\n",
    "        loss = crit(m(Xt), yt)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if (e + 1) % 10 == 0:\n",
    "            log(f'  Epoch {e + 1}/{epochs} Loss: {loss.item():.6f}')\n",
    "    torch.save(m.state_dict(), PYTORCH_WEIGHTS)\n",
    "    log(f'Saved: {PYTORCH_WEIGHTS}')\n",
    "\n",
    "def train_tensorflow(X, y, epochs, log):\n",
    "    log(f'Training TensorFlow ({epochs} epochs)...')\n",
    "    m = create_tf_model((X.shape[1], X.shape[2]))\n",
    "    m.fit(X, y, epochs=epochs, batch_size=max(1, len(X) // 10), verbose=0)\n",
    "    m.save(TF_WEIGHTS)\n",
    "    log(f'Saved: {TF_WEIGHTS}')\n",
    "\n",
    "def train_randomforest(X, y, log):\n",
    "    log('Training RandomForest...')\n",
    "    Xf = X.reshape(X.shape[0], -1)\n",
    "    m = create_rf_model()\n",
    "    m.fit(Xf, y)\n",
    "    with open(RF_WEIGHTS, 'wb') as f:\n",
    "        pickle.dump(m, f)\n",
    "    log(f'Saved: {RF_WEIGHTS}')\n",
    "\n",
    "out = widgets.Output(layout={'height': '300px', 'overflow': 'auto', 'border': '1px solid #999'})\n",
    "\n",
    "token_w = widgets.Dropdown(options=TOKENS, value='bitcoin', description='Token:')\n",
    "days_w = widgets.IntText(value=30, description='Days:')\n",
    "epochs_w = widgets.IntText(value=50, description='Epochs:')\n",
    "model_w = widgets.RadioButtons(\n",
    "    options=[('PyTorch', 'pytorch'), ('TensorFlow', 'tensorflow'), ('RandomForest', 'randomforest'), ('All', 'all')],\n",
    "    value='all',\n",
    "    description='Model:'\n",
    ")\n",
    "train_btn = widgets.Button(description='Start Training', button_style='success')\n",
    "\n",
    "def log(msg):\n",
    "    with out:\n",
    "        print(msg)\n",
    "\n",
    "def run_train(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "    token, days, epochs, model = token_w.value, days_w.value, epochs_w.value, model_w.value\n",
    "    log(f'Config: token={token}, days={days}, epochs={epochs}, model={model}')\n",
    "\n",
    "    df = fetch_and_parse(token, days)\n",
    "    if df is None or len(df) < 10:\n",
    "        log('Error: not enough data')\n",
    "        return\n",
    "\n",
    "    log(f'Data rows: {len(df)}')\n",
    "    df_proc, _ = preprocess_data(df, fit_scaler=True)\n",
    "    features = df_proc[['price', 'volume', 'sentiment', 'volatility', 'price_lag1']]\n",
    "    X, y = create_sequences(features, min(10, len(features) // 2))\n",
    "    if len(X) == 0:\n",
    "        log('Error: not enough sequences')\n",
    "        return\n",
    "\n",
    "    split = max(1, int(0.8 * len(X)))\n",
    "    X_train, y_train = X[:split], y[:split]\n",
    "    log(f'Training sequences: {len(X_train)}')\n",
    "\n",
    "    if model in ['pytorch', 'all']:\n",
    "        train_pytorch(X_train, y_train, epochs, log)\n",
    "    if model in ['tensorflow', 'all']:\n",
    "        train_tensorflow(X_train, y_train, epochs, log)\n",
    "    if model in ['randomforest', 'all']:\n",
    "        train_randomforest(X_train, y_train, log)\n",
    "\n",
    "    log('')\n",
    "    log('Training complete. Files in weights dir:')\n",
    "    for name in sorted(os.listdir(WEIGHTS_DIR)):\n",
    "        log(f'  - {name}')\n",
    "\n",
    "train_btn.on_click(run_train)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML('<h3>Training Panel</h3>'),\n",
    "    token_w,\n",
    "    days_w,\n",
    "    epochs_w,\n",
    "    model_w,\n",
    "    train_btn,\n",
    "    out\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
