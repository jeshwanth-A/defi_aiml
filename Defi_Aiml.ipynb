{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO78NBjXNt1To0JQ93aYjY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeshwanth-A/defi_aiml/blob/main/Defi_Aiml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaTfkdwCt1Cv"
      },
      "outputs": [],
      "source": [
        "import os, warnings\n",
        "os.environ['JUPYTER_WIDGETS_ENABLED'] = 'false'\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from IPython import get_ipython\n",
        "if get_ipython():\n",
        "    get_ipython().run_line_magic('config', \"InlineBackend.figure_formats = ['png']\")\n",
        "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "\n",
        "!pip install -q numpy pandas torch torchvision torchaudio\n",
        "!pip install -q tensorflow\n",
        "!pip install -q scikit-learn matplotlib\n",
        "!pip install -q transformers peft datasets accelerate\n",
        "!pip install -q huggingface-hub\n",
        "\n",
        "import urllib.request\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from datasets import Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_folder = '/content/drive/MyDrive/crypto_project'\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "pt_model_path = os.path.join(save_folder, 'model_pt.pth')\n",
        "tf_model_path = os.path.join(save_folder, 'model_tf.h5')\n",
        "llm_path = os.path.join(save_folder, 'finetuned_llm')\n",
        "data_path = os.path.join(save_folder, 'processed_data.csv')\n",
        "\n",
        "def fetch_and_parse(token_id='uniswap', days=30):\n",
        "    url = f\"https://api.coingecko.com/api/v3/coins/{token_id}/market_chart?vs_currency=usd&days={days}&interval=daily\"\n",
        "    try:\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            data = response.read().decode(\"utf-8\")\n",
        "            json_data = json.loads(data)\n",
        "\n",
        "        required_keys = ['prices', 'total_volumes']\n",
        "        for key in required_keys:\n",
        "            if key not in json_data:\n",
        "                return None\n",
        "\n",
        "        prices = json_data.get('prices', [])\n",
        "        volumes = json_data.get('total_volumes', [])\n",
        "\n",
        "        if len(prices) == 0 or len(volumes) == 0:\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
        "        df['volume'] = [v[1] for v in volumes]\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def add_sentiment(df):\n",
        "    np.random.seed(42)\n",
        "    df['sentiment'] = np.random.uniform(-1, 1, size=len(df))\n",
        "    return df\n",
        "\n",
        "def create_sequences(data, seq_len=10):\n",
        "    seq_len = min(seq_len, len(data) - 1)\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data.iloc[i:i+seq_len].values)\n",
        "        y.append(data.iloc[i+seq_len]['price'])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "class PricePredictor(nn.Module):\n",
        "    def __init__(self, input_size=5, hidden_size=50, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    df = pd.read_csv(data_path)\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "else:\n",
        "    df = fetch_and_parse(token_id='uniswap', days=30)\n",
        "\n",
        "    if df is not None:\n",
        "        df = df.dropna()\n",
        "\n",
        "        df = add_sentiment(df)\n",
        "\n",
        "        prices_np = df['price'].values\n",
        "        window_size = min(5, len(prices_np))\n",
        "\n",
        "        if len(prices_np) >= window_size:\n",
        "            volatility = np.std(\n",
        "                np.lib.stride_tricks.sliding_window_view(prices_np, window_size),\n",
        "                axis=1\n",
        "            )\n",
        "            df['volatility'] = np.pad(volatility, (window_size-1, 0), mode='edge')\n",
        "        else:\n",
        "            df['volatility'] = 0\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        df[['price', 'volume', 'sentiment', 'volatility']] = scaler.fit_transform(\n",
        "            df[['price', 'volume', 'sentiment', 'volatility']]\n",
        "        )\n",
        "\n",
        "        df['price_lag1'] = df['price'].shift(1)\n",
        "        df = df.dropna()\n",
        "\n",
        "        df.to_csv(data_path, index=False)\n",
        "    else:\n",
        "        df = None\n",
        "\n",
        "if df is not None and len(df) > 0:\n",
        "    features = df[['price', 'volume', 'sentiment', 'volatility', 'price_lag1']]\n",
        "    seq_length = min(10, len(features) // 2)\n",
        "    X, y = create_sequences(features, seq_len=seq_length)\n",
        "\n",
        "    if len(X) > 0:\n",
        "        split = max(1, int(0.8 * len(X)))\n",
        "        X_train, X_test = X[:split], X[split:]\n",
        "        y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "        if len(X_train) > 0:\n",
        "            rf = RandomForestRegressor(n_estimators=50, random_state=42, max_depth=10)\n",
        "            rf.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "            rf_preds = rf.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "            rf_mae = mean_absolute_error(y_test, rf_preds)\n",
        "\n",
        "        model_pt = PricePredictor(input_size=X_train.shape[2])\n",
        "\n",
        "        if os.path.exists(pt_model_path):\n",
        "            model_pt.load_state_dict(torch.load(pt_model_path))\n",
        "        else:\n",
        "            optimizer = torch.optim.Adam(model_pt.parameters(), lr=0.001)\n",
        "            criterion = nn.MSELoss()\n",
        "            X_train_pt = torch.tensor(X_train, dtype=torch.float32)\n",
        "            y_train_pt = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "            for epoch in range(50):\n",
        "                model_pt.train()\n",
        "                outputs = model_pt(X_train_pt)\n",
        "                loss = criterion(outputs, y_train_pt)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            torch.save(model_pt.state_dict(), pt_model_path)\n",
        "\n",
        "        model_pt.eval()\n",
        "        with torch.no_grad():\n",
        "            X_test_pt = torch.tensor(X_test, dtype=torch.float32)\n",
        "            preds_pt = model_pt(X_test_pt).numpy()\n",
        "\n",
        "        pt_mae = mean_absolute_error(y_test, preds_pt.flatten())\n",
        "\n",
        "        if os.path.exists(tf_model_path):\n",
        "            try:\n",
        "                model_tf = tf.keras.models.load_model(\n",
        "                    tf_model_path,\n",
        "                    custom_objects={'mse': tf.keras.losses.MeanSquaredError()}\n",
        "                )\n",
        "            except Exception as e:\n",
        "                os.remove(tf_model_path)\n",
        "                model_tf = None\n",
        "        else:\n",
        "            model_tf = None\n",
        "\n",
        "        if model_tf is None:\n",
        "            model_tf = Sequential([\n",
        "                LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                Dense(1)\n",
        "            ])\n",
        "            model_tf.compile(\n",
        "                optimizer='adam',\n",
        "                loss=tf.keras.losses.MeanSquaredError()\n",
        "            )\n",
        "\n",
        "            history = model_tf.fit(\n",
        "                X_train, y_train,\n",
        "                epochs=50,\n",
        "                batch_size=max(1, len(X_train)//10),\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            model_tf.save(tf_model_path)\n",
        "\n",
        "        preds_tf = model_tf.predict(X_test, verbose=0)\n",
        "        tf_mae = mean_absolute_error(y_test, preds_tf.flatten())\n",
        "\n",
        "        explanation_data = {\n",
        "            'text': [\n",
        "                \"The prediction was close to actual value, showing good model performance.\",\n",
        "                \"Large prediction error indicates model needs improvement.\",\n",
        "                \"Price increased but prediction was lower, missing upward trend.\",\n",
        "                \"Sentiment was positive and price rose as expected.\"\n",
        "            ],\n",
        "            'label': [1, 0, 0, 1]\n",
        "        }\n",
        "        dataset = Dataset.from_dict(explanation_data)\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "        def preprocess(examples):\n",
        "            return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "        dataset = dataset.map(preprocess, batched=True)\n",
        "        dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "        if os.path.exists(os.path.join(llm_path, 'adapter_config.json')):\n",
        "            base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                \"distilbert-base-uncased\", num_labels=2\n",
        "            )\n",
        "            model_llm = PeftModel.from_pretrained(base_model, llm_path)\n",
        "        else:\n",
        "            lora_config = LoraConfig(\n",
        "                r=8,\n",
        "                lora_alpha=32,\n",
        "                target_modules=[\"q_lin\", \"v_lin\"],\n",
        "                lora_dropout=0.1,\n",
        "                bias=\"none\",\n",
        "                task_type=\"SEQ_CLS\"\n",
        "            )\n",
        "            base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                \"distilbert-base-uncased\", num_labels=2\n",
        "            )\n",
        "            model_llm = get_peft_model(base_model, lora_config)\n",
        "\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir=\"./results\",\n",
        "                num_train_epochs=3,\n",
        "                per_device_train_batch_size=2,\n",
        "                save_strategy=\"epoch\",\n",
        "                logging_steps=10,\n",
        "                report_to=\"none\"\n",
        "            )\n",
        "            trainer = Trainer(\n",
        "                model=model_llm,\n",
        "                args=training_args,\n",
        "                train_dataset=dataset\n",
        "            )\n",
        "            trainer.train()\n",
        "            model_llm.save_pretrained(llm_path)\n",
        "\n",
        "        fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "        plt.subplot(2, 2, 1)\n",
        "        test_indices = range(len(y_test))\n",
        "        plt.plot(test_indices, y_test, 'g-', label='Actual', linewidth=2.5, marker='o', markersize=4)\n",
        "        plt.plot(test_indices, preds_pt.flatten(), 'b--', label='PyTorch LSTM', alpha=0.8, linewidth=2)\n",
        "        plt.plot(test_indices, preds_tf.flatten(), 'r--', label='TensorFlow LSTM', alpha=0.8, linewidth=2)\n",
        "        plt.xlabel('Test Sample Index', fontsize=11)\n",
        "        plt.ylabel('Normalized Price', fontsize=11)\n",
        "        plt.title('Model Predictions vs Actual Price', fontsize=13, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.subplot(2, 2, 2)\n",
        "        pt_errors = np.abs(y_test - preds_pt.flatten())\n",
        "        tf_errors = np.abs(y_test - preds_tf.flatten())\n",
        "        rf_errors = np.abs(y_test - rf_preds)\n",
        "        plt.plot(test_indices, pt_errors, 'b-', label='PyTorch Error', alpha=0.7, linewidth=2)\n",
        "        plt.plot(test_indices, tf_errors, 'r-', label='TensorFlow Error', alpha=0.7, linewidth=2)\n",
        "        plt.plot(test_indices, rf_errors, 'g-', label='Random Forest Error', alpha=0.5, linewidth=1.5)\n",
        "        plt.xlabel('Test Sample Index', fontsize=11)\n",
        "        plt.ylabel('Absolute Error', fontsize=11)\n",
        "        plt.title('Prediction Errors Comparison', fontsize=13, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.subplot(2, 2, 3)\n",
        "        recent_data = df.tail(len(y_test))\n",
        "        plt.plot(recent_data['sentiment'].values, label='Sentiment', alpha=0.8, linewidth=2, color='purple')\n",
        "        plt.plot(recent_data['volatility'].values, label='Volatility', alpha=0.8, linewidth=2, color='orange')\n",
        "        plt.xlabel('Time Index', fontsize=11)\n",
        "        plt.ylabel('Normalized Value', fontsize=11)\n",
        "        plt.title('Sentiment & Volatility Trends', fontsize=13, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.subplot(2, 2, 4)\n",
        "        models = ['Random\\nForest', 'PyTorch\\nLSTM', 'TensorFlow\\nLSTM']\n",
        "        maes = [rf_mae, pt_mae, tf_mae]\n",
        "        colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "        bars = plt.bar(models, maes, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "        for bar, mae in zip(bars, maes):\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{mae:.4f}',\n",
        "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "        plt.ylabel('Mean Absolute Error', fontsize=11)\n",
        "        plt.title('Model Performance Comparison', fontsize=13, fontweight='bold')\n",
        "        plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        viz_path = os.path.join(save_folder, 'forecast_viz.png')\n",
        "        plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close('all')"
      ]
    }
  ]
}